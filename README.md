# siniestros_viales
Proyecto de procesamiento de siniestros viales con Kafka y Spar
Perfecto üî• Aqu√≠ tienes un **README.md completo y profesional**, listo para que lo copies y pegues en tu repositorio de GitHub (`siniestros_viales`).
Solo reemplaza tu nombre en la parte final si quieres personalizarlo.

---

````markdown
# üö¶ Proyecto: Procesamiento de Siniestros Viales con Kafka y Spark

Este proyecto implementa una soluci√≥n de **procesamiento de datos en tiempo real** utilizando **Apache Kafka** y **Apache Spark Streaming**, aplic√°ndolo al an√°lisis de siniestros viales en la ciudad de Bogot√°.  

---

## üß© Descripci√≥n del Proyecto

El sistema permite leer un conjunto de datos con informaci√≥n sobre siniestros viales, enviar los registros a un **topic de Kafka**, y procesarlos en tiempo real usando **Spark Structured Streaming**.  
Con ello se pueden realizar an√°lisis como:
- Conteo de siniestros por tipo.  
- An√°lisis por localidad.  
- Filtrado de siniestros con v√≠ctimas o condiciones espec√≠ficas.  

---

## üóÇÔ∏è Conjunto de Datos

El dataset utilizado es **`siniestros_viales_bogota.csv`**, que contiene columnas como:
- Fecha del siniestro  
- Tipo de accidente  
- Localidad  
- N√∫mero de heridos y fallecidos  
- Condiciones clim√°ticas  

üìç **Fuente:** Datos abiertos de la Alcald√≠a de Bogot√° (o fuente utilizada en tu pr√°ctica).



## üñ•Ô∏è Requisitos del Entorno

* Ubuntu o Linux (VirtualBox recomendado)
* Apache Kafka instalado
* Apache Spark con PySpark
* Python 3.8 o superior

---

## üöÄ Pasos para la Ejecuci√≥n

### 1Ô∏è‚É£ Iniciar Kafka

```bash
/opt/Kafka/bin/kafka-server-start.sh /opt/Kafka/config/server.properties
```

### 2Ô∏è‚É£ Crear el Topic

```bash
/opt/Kafka/bin/kafka-topics.sh --create --topic siniestros_viales --bootstrap-server localhost:9092
```

### 3Ô∏è‚É£ Enviar Datos al Topic

Puedes enviar datos manualmente:

```bash
/opt/Kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic siniestros_viales
```

O automatizarlo con un script (`kafka_setup.sh`):

```bash
bash kafka_setup.sh
```

### 4Ô∏è‚É£ Ejecutar Spark Streaming

```bash
python3 spark_kafka_stream.py
```

### 5Ô∏è‚É£ Visualizar los Resultados

En la terminal ver√°s la salida del DataFrame en tiempo real, con los siniestros procesados y los an√°lisis generados.

---

## üìä Explicaci√≥n del DataFrame

Un **DataFrame** en Spark es una estructura tabular distribuida (similar a una tabla SQL).
En este proyecto:

* Cada mensaje que llega desde Kafka se convierte en una **fila del DataFrame**.
* Se aplican transformaciones (`select`, `groupBy`, `agg`, etc.) para analizar los datos.
* Las operaciones se ejecutan en paralelo, aprovechando el motor distribuido de Spark.

Ejemplo:

```python
df_siniestros = spark.readStream.format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "siniestros_viales") \
    .load()

df_siniestros.selectExpr("CAST(value AS STRING)").show()
```

---

## üì∑ Resultados Esperados

* Conteo de siniestros por tipo o localidad.
* Filtrado de registros con condiciones espec√≠ficas.
* Visualizaci√≥n en consola o almacenamiento en archivos/parquet.


---

## Autor

**Wilson Stiven rojas diaz**
Proyecto acad√©mico ‚Äì Procesamiento de datos en tiempo real con Apache Kafka y Spark Streaming.
Universidad / Curso: big data

